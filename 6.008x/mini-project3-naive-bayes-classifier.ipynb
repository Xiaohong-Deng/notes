{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini project 3 naive bayes classifier\n",
    "## review\n",
    "#### Bayes Inference and MAP estimation\n",
    "Recall that given the belief we have on some random variable, after we obtain a sequence of sample observations, how we gonna change our belief on that random variable? This process is called **Bayes Inference**.\n",
    "\n",
    "For example, we assume a coin is fair. After a few coin flips, how we are going to change our belief of the coin being fair? The distribution of being heads and tails is no longer fifty fifty. Furthermore, what value would we give to predict the next flip given our changed belief? That would be the value that gives us the maximum probability in that distribution. The value is called **MAP estimation**.\n",
    "\n",
    "Same rule could be applied to other random variables in the coin flip experiment. For example, we could set the random variable to be **the probability that a coin flip results in heads**, let's call it $\\theta$.\n",
    "\n",
    "Say we are looking for the MAP estimation of $\\theta$. $$\\hat{\\theta} =  \\arg\\max_{\\theta \\in [0, 1]}{P}_{X^{(1)}, X^{(2)}, X^{(3)} \\mid \\Theta}(H, T, H \\mid \\theta) \\times P_{\\Theta}(\\theta)$$\n",
    "\n",
    "$$ = \\arg\\max_{\\theta \\in [0, 1]}\\frac{{P}_{X^{(1)}, X^{(2)}, X^{(3)} \\mid \\Theta}(H, T, H \\mid \\theta) \\times P_{\\Theta}(\\theta)}{P_{X^{(1)}, X^{(2)}, X^{(3)}}(H, T, H)} $$\n",
    "\n",
    "The first RHS is the joint probability of the observations we see and $\\theta$. The second RHS is the posterior of $\\theta$, meaning after we obtain the observations how we are going to change our belief on the distribution of $\\theta$ and which particular value that $\\theta$ could take on results in the highest probability? The $\\theta$ makes the first largest also makes the second largest because the denominator in the second doesn't involve $\\theta$.\n",
    "\n",
    "#### Laplace Smoothing\n",
    "If we set the prior for $\\theta$ to be $\\theta^m(1-\\theta)^n$ for $\\theta \\in [0, 1]$, then the first RHS will be $\\theta^{2+m}(1-\\theta)^{1+n}$. From **ML** estimation we know it's like $m+2$ heads and $n+1$ tails. That's intuitive because if we don't have enough sample observations we rely on the prior more with $m$ and $n$ pseudo counts. This is called Laplace Smoothing.\n",
    "\n",
    "## setup\n",
    "Before predicting an email being ham or spam, from training set we know the prior probability of an email being spam or ham. We also know for each word in the spam emails the requency it makes its appearance in the spam emails. Same apllies to the hams.\n",
    "\n",
    "## analysis\n",
    "There are two stages in the email classifier.\n",
    "- training stage\n",
    "- predicting stage\n",
    "\n",
    "In the training stage, the problem is what is $\\theta$ and what is the function we want to maximize that involves $\\theta$? Given we know which emails are hams or spams and the word frequencies, the function is set to be the probability that we see the training data. Recall we have $n$ training emails.\n",
    "\n",
    "$$\\widehat{\\theta } = \\arg \\max _\\theta \\prod _{i=1}^ n p_{C, Y_1, \\dots , Y_ J}(c^{(i)}, y_1^{(i)}, \\dots , y_ J^{(i)}; \\theta )$$\n",
    "\n",
    "The $\\theta$ is\n",
    "\n",
    "$$\\theta =\\{ s,p_{1},p_{2},\\dots ,p_{J},q_{1},q_{2},\\dots ,q_{J}\\}$$\n",
    "\n",
    "$s$ is the prior probability of an email being spam, $p_i$ is the probability of a word showing in an email given the email is spam. $q_i$ is the counterpart for ham. It maybe not obvious at the first glance, they will be in the function we want to maximize. $c$ takes on values $\\{0, 1\\}$ to represent if the email is a spam or ham. $y_i$ takes on values $\\{0, 1\\}$ to represent if word $i$ appears in the email.\n",
    "\n",
    "Up to this point you can see we are using **ML** estimation instead of **MAP** estimation. We don't assume a prior distribution of $\\theta$\n",
    "\n",
    "#### Laplace Smoothing in the play\n",
    "If there is a word in a testing email doesn't appear in the training set, we can fix it by adding pseudo counts. Specifically, for $p_i$ add 1 to the numerator and 2 to the denominator. This means for each word in hams or spams, we pretend we add two more spams or hams and one of them has the word $i$.\n",
    "\n",
    "In the predicting stage, we are asked that if we know the words it has it's more likely to be a spam or ham? That's conditional probability we can derive from **Bayes rules**. Becuase we are going to compare $P(ham)$ and $P(spam)$ by taking their ratio, and their denominator are the same, **we don't need to calculate the denominator**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
